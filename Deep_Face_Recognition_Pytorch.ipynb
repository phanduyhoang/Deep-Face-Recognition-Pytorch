{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-yOaBNQrBrgr"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/negative.zip -d /content/lfw-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Flatten, Dense, Layer\n",
        "import torch.nn.functional as F\n",
        "# from torch.nn import Model, Conv2d, Upsample, Flatten, Linear, MaxPool2d\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"available GPUS:\")\n",
        "  for i in range(torch.cuda.device_count()):\n",
        "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "\n",
        "\n",
        "POS_PATH=os.path.join('data','positive')\n",
        "NEG_PATH=os.path.join('data','negative')\n",
        "ANC_PATH=os.path.join('data','anchor')\n",
        "os.makedirs(POS_PATH, exist_ok=True)\n",
        "os.makedirs(NEG_PATH, exist_ok=True)\n",
        "os.makedirs(ANC_PATH, exist_ok=True)\n",
        "\n",
        "print(\"Directories created successfully!\")\n",
        "\n",
        "import os\n",
        "for directory in os.listdir('/content/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'):\n",
        "    for file in os.listdir(os.path.join('/content/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled', directory)):\n",
        "        EX_PATH = os.path.join('/content/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled', directory, file)\n",
        "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
        "        os.replace(EX_PATH, NEW_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeSaGvd6B2CH",
        "outputId": "b9551406-4449-488d-efa4-61c75bd5de85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#For some reason this code can only crawl positive images. I needed to create another code for negative iamges\n",
        "!pip install icrawler Pillow mtcnn\n",
        "\n",
        "import os  # Added import\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "from PIL import Image, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "from mtcnn import MTCNN\n",
        "import numpy as np\n",
        "import shutil\n",
        "import uuid\n",
        "\n",
        "def scrape_and_store_images(person_name, num_images, positive_path, anchor_path):\n",
        "    # Ensure the save paths exist\n",
        "    if not os.path.exists(positive_path):\n",
        "        os.makedirs(positive_path)\n",
        "        print(f\"Created directory: {positive_path}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {positive_path}\")\n",
        "\n",
        "    if not os.path.exists(anchor_path):\n",
        "        os.makedirs(anchor_path)\n",
        "        print(f\"Created directory: {anchor_path}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {anchor_path}\")\n",
        "\n",
        "    # Initialize the Bing crawler\n",
        "    crawler = BingImageCrawler(storage={\"root_dir\": \"temp_images\"})\n",
        "    print(f\"Starting image crawl for '{person_name}' with max_num={num_images}\")\n",
        "    crawler.crawl(keyword=person_name, max_num=num_images)  # Download specified number of images\n",
        "    print(\"Image crawling completed.\")\n",
        "\n",
        "    # Process each downloaded image\n",
        "    image_files = [f for f in os.listdir(\"temp_images\") if f.endswith(('jpg', 'jpeg', 'png'))]\n",
        "    print(f\"Number of images downloaded: {len(image_files)}\")\n",
        "\n",
        "    if not image_files:\n",
        "        raise FileNotFoundError(\"No images were downloaded. Please refine your search query.\")\n",
        "\n",
        "    detector = MTCNN()\n",
        "    saved_count = 0\n",
        "    for idx, image_file in enumerate(image_files):\n",
        "        image_path = os.path.join(\"temp_images\", image_file)\n",
        "        try:\n",
        "            downloaded_image = Image.open(image_path).convert(\"RGB\")  # Ensure the image is in RGB mode\n",
        "            image_np = np.array(downloaded_image)  # Convert to NumPy array for MTCNN\n",
        "\n",
        "            # Detect faces\n",
        "            faces = detector.detect_faces(image_np)\n",
        "            if faces:\n",
        "                # Get the first detected face's bounding box\n",
        "                x, y, width, height = faces[0][\"box\"]\n",
        "\n",
        "                # Expand the bounding box by 30%\n",
        "                expansion_factor = 0.3\n",
        "                x_expand = int(width * expansion_factor)\n",
        "                y_expand = int(height * expansion_factor)\n",
        "\n",
        "                # Calculate the new bounding box coordinates\n",
        "                x_new = max(0, x - x_expand)\n",
        "                y_new = max(0, y - y_expand)\n",
        "                width_new = min(downloaded_image.width, x + width + x_expand) - x_new\n",
        "                height_new = min(downloaded_image.height, y + height + y_expand) - y_new\n",
        "\n",
        "                # Crop the expanded face region\n",
        "                cropped_face = downloaded_image.crop((x_new, y_new, x_new + width_new, y_new + height_new))\n",
        "\n",
        "                # Pad to maintain aspect ratio\n",
        "                max_side = max(cropped_face.size)\n",
        "                padded_face = ImageOps.expand(\n",
        "                    cropped_face,\n",
        "                    border=(max_side - cropped_face.width) // 2,\n",
        "                    fill=(0, 0, 0)\n",
        "                )\n",
        "\n",
        "                # Resize to 250x250\n",
        "                resized_face = padded_face.resize((250, 250))\n",
        "\n",
        "                # Save the processed image with a unique name\n",
        "                save_path = positive_path if idx < num_images // 2 else anchor_path  # Split into positive and anchor\n",
        "                filename = f\"{uuid.uuid4().hex}.jpg\"\n",
        "                save_path_full = os.path.join(save_path, filename)\n",
        "                resized_face.save(save_path_full)\n",
        "\n",
        "                print(f\"Saved: {save_path_full}\")\n",
        "                saved_count += 1\n",
        "\n",
        "            else:\n",
        "                print(f\"No face detected in {image_file}. Skipping.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_file}: {e}\")\n",
        "\n",
        "    print(f\"Total images saved: {saved_count}\")\n",
        "\n",
        "    # Clean up temporary folder\n",
        "    shutil.rmtree(\"temp_images\")\n",
        "    print(\"Temporary images folder removed.\")\n",
        "\n",
        "# Example usage\n",
        "POS_PATH = os.path.join('data', 'positive')\n",
        "ANCHOR_PATH = os.path.join('data', 'anchor')\n",
        "scrape_and_store_images(\n",
        "    person_name=\"Elon Musk\",\n",
        "    num_images=800,\n",
        "    positive_path=POS_PATH,\n",
        "    anchor_path=ANC_PATH  # Corrected variable name\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwX4OHeyB6lO",
        "outputId": "37e51ec9-8d97-4109-f82c-07678592452d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.9-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting mtcnn\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from icrawler) (4.12.3)\n",
            "Collecting bs4 (from icrawler)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from icrawler) (5.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from icrawler) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from icrawler) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from icrawler) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn)\n",
            "  Downloading lz4-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2024.12.14)\n",
            "Downloading icrawler-0.6.9-py3-none-any.whl (34 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: lz4, mtcnn, bs4, icrawler\n",
            "Successfully installed bs4-0.0.2 icrawler-0.6.9 lz4-4.3.3 mtcnn-1.0.0\n",
            "Directory already exists: data/positive\n",
            "Directory already exists: data/anchor\n",
            "Starting image crawl for 'Elon Musk' with max_num=800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Exception caught when downloading file https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/7GZY2GHEDQI6XCGFJ7LDQLCHZM.jpg, error: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=5), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/7GZY2GHEDQI6XCGFJ7LDQLCHZM.jpg, error: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=5), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/7GZY2GHEDQI6XCGFJ7LDQLCHZM.jpg, error: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=5), remaining retry times: 0\n",
            "ERROR:downloader:Response status code 520, file https://itrenting.com/wp-content/uploads/2017/04/elon-musk.jpg\n",
            "ERROR:downloader:Response status code 403, file https://www.theladders.com/wp-content/uploads/Elon_Musk.jpg\n",
            "ERROR:downloader:Exception caught when downloading file https://apidyn.royalsociety.org/images/fellows/P37009-Elon-Musk.jpg, error: HTTPSConnectionPool(host='apidyn.royalsociety.org', port=443): Max retries exceeded with url: /images/fellows/P37009-Elon-Musk.jpg (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://apidyn.royalsociety.org/images/fellows/P37009-Elon-Musk.jpg, error: HTTPSConnectionPool(host='apidyn.royalsociety.org', port=443): Max retries exceeded with url: /images/fellows/P37009-Elon-Musk.jpg (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://apidyn.royalsociety.org/images/fellows/P37009-Elon-Musk.jpg, error: HTTPSConnectionPool(host='apidyn.royalsociety.org', port=443): Max retries exceeded with url: /images/fellows/P37009-Elon-Musk.jpg (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))), remaining retry times: 0\n",
            "ERROR:downloader:Response status code 403, file https://www.ccn.com/wp-content/uploads/2019/04/elon-musk-tesla-red.jpg\n",
            "ERROR:downloader:Response status code 400, file https://www.alternet.org/media-library/donald-trump-and-elon-musk-watch-the-launch-of-the-sixth-test-flight-of-the-spacex-starship-rocket-in-brownsville-texas-u-s.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image crawling completed.\n",
            "Number of images downloaded: 283\n",
            "Saved: data/positive/044faf20c163408c9a382703b6e01fae.jpg\n",
            "Saved: data/positive/0b84305920284043af767718db151592.jpg\n",
            "Saved: data/positive/abaa8ebaced9494297c0e777a6b498cb.jpg\n",
            "Saved: data/positive/d960b5bdf1994613a400998d122b0287.jpg\n",
            "Saved: data/positive/1441cc10121243bdab3fc84ca7bae495.jpg\n",
            "Saved: data/positive/51ccda15f7b14e83bd33937780fdb8b6.jpg\n",
            "Saved: data/positive/ab175452a05c4fe7a2375e22afa08539.jpg\n",
            "Saved: data/positive/af084815cee84c23885dfaa9df4899b4.jpg\n",
            "Saved: data/positive/00f40a5cec694eaca41020b6e63a7dc5.jpg\n",
            "Saved: data/positive/2e2e2a15de044222b64a0cc1996c673a.jpg\n",
            "Saved: data/positive/8e93fd0625a549f7be74a95e09356a7c.jpg\n",
            "Saved: data/positive/021dc4e9ab6b4c729a5de557d4d03c5f.jpg\n",
            "Saved: data/positive/72fca6081d5b43849ebc37a60981fd71.jpg\n",
            "No face detected in 000265.jpg. Skipping.\n",
            "Saved: data/positive/6fafe6c696174c439b04e87e538b0099.jpg\n",
            "Saved: data/positive/14bb7cda68f843629323ca5119bfefab.jpg\n",
            "Saved: data/positive/9a3f5de0f49448a6b3212c87439812d8.jpg\n",
            "Saved: data/positive/c7c6dc54757d448a992909cedcef9486.jpg\n",
            "Saved: data/positive/e1124e221fad4b3ba6247feef6cc02d5.jpg\n",
            "Saved: data/positive/9a904600646243bd88043c79498b22ff.jpg\n",
            "No face detected in 000279.jpg. Skipping.\n",
            "Saved: data/positive/c648962299a6437d8332d115452af40f.jpg\n",
            "No face detected in 000282.jpg. Skipping.\n",
            "Saved: data/positive/0035a1be434c4d7c987ed538650381bc.jpg\n",
            "Saved: data/positive/ee34786c8a834c69958b8dee20880037.jpg\n",
            "Saved: data/positive/9354ca1f52d244f5abe5aa9affdfdf80.jpg\n",
            "Saved: data/positive/d28795ff007c4bb098d4b43ecc67bfdd.jpg\n",
            "Saved: data/positive/31bb2fcca13b44cd950297c22c450943.jpg\n",
            "Saved: data/positive/582fa7f478c148adae492d05049bd401.jpg\n",
            "Saved: data/positive/235a338bcc224e08b68c1dac6b5b6a8e.jpg\n",
            "Saved: data/positive/a138d6467439474799a386d1f4fdf068.jpg\n",
            "Saved: data/positive/6c5846c6937543d98a5591c3cc2d5038.jpg\n",
            "Saved: data/positive/37e90167d1a74b70aeb54bbb141001e6.jpg\n",
            "Saved: data/positive/79c37bd20f5c47578bc642c6b196bbd3.jpg\n",
            "Saved: data/positive/89a36979b0b747f0b6a6851241590e8d.jpg\n",
            "Saved: data/positive/4d7921b2b3734c94b94ba589726f03f8.jpg\n",
            "Saved: data/positive/23b335908dae4493b56bf6bcc5ee7e56.jpg\n",
            "Saved: data/positive/b0d381b80d2649dca10249ab1717f2c2.jpg\n",
            "Saved: data/positive/af96ccde974f4c3f93e1cb4aba6dad8e.jpg\n",
            "Saved: data/positive/b7f0f7af15154cfd8fbcffd156b7fe50.jpg\n",
            "Saved: data/positive/775b101b24cc4fd7ad0195ac2a5a5b53.jpg\n",
            "Saved: data/positive/03c13bbe50f74bf388acd5a116a89e99.jpg\n",
            "Saved: data/positive/2a5a9895a5f7463e85f83736626be3b7.jpg\n",
            "Saved: data/positive/3a2681565b934debb00920b40c08bf6f.jpg\n",
            "Saved: data/positive/8b7cd17dedb54b078b31c54c19deb9cc.jpg\n",
            "Saved: data/positive/00e0e53171cb4357a972ad1e1a9205a6.jpg\n",
            "Saved: data/positive/0e9d9f73c1b34496bbbd4b1145ef4859.jpg\n",
            "Saved: data/positive/44bcf68fd4a0426ebee993cb68e599f2.jpg\n",
            "Saved: data/positive/975183eadd9640bbadd48b0adcc19bbe.jpg\n",
            "Saved: data/positive/b0bfbc56beb24d61a7ba7ebbda638432.jpg\n",
            "Saved: data/positive/f3a19ea028424cf7b3804864dcc1d649.jpg\n",
            "Saved: data/positive/3befcc81dc944c5d9a087ba36641806a.jpg\n",
            "Saved: data/positive/2e512f27a2e84532805436cccee1b61a.jpg\n",
            "Saved: data/positive/39dde84e28e7428291a8b4d546b2858a.jpg\n",
            "Saved: data/positive/280613c4d4594e97b99cf918ba6a161f.jpg\n",
            "Saved: data/positive/bd26e8c7b0924e23ab9705fe53f2143c.jpg\n",
            "Saved: data/positive/c900e53273324e46a9fe31dbb10a21a3.jpg\n",
            "Saved: data/positive/0bc1efa7d55d4c21b2676ac97b303f9d.jpg\n",
            "Saved: data/positive/34ef68d3da5b4e019b4e2fbf11727d3a.jpg\n",
            "Saved: data/positive/17f005f575de4b96bfe0fb7e17ac31da.jpg\n",
            "Saved: data/positive/5acf3f29abac4566af4543eadd5b8012.jpg\n",
            "Saved: data/positive/5347310c3a094096995c75ea59f34eb7.jpg\n",
            "Saved: data/positive/867206232d734ca39c74bdad957c4856.jpg\n",
            "Saved: data/positive/9cc921d2d697493aa40d288ab04731d4.jpg\n",
            "Saved: data/positive/5d0c38eea8e545cf8feb919d10e41b17.jpg\n",
            "Saved: data/positive/3aaaed0402d9435c8f10bde9721b2e64.jpg\n",
            "Saved: data/positive/9e6f5075db75409aaefd640e7e75d2e6.jpg\n",
            "Saved: data/positive/9ee3d87b7bcd432191b5df754434e546.jpg\n",
            "Saved: data/positive/ee19d1dc435f4bf88726ec0c72539213.jpg\n",
            "Saved: data/positive/ad4b1315a3ee4c6994d903c7fc73ce6e.jpg\n",
            "Saved: data/positive/f112d12a6b7840d290fcdcabaf1e1241.jpg\n",
            "Saved: data/positive/b34cac87e32e480a90bbd3b8d2fd3a0e.jpg\n",
            "Saved: data/positive/33842963248a4192906e3f87ab241487.jpg\n",
            "Saved: data/positive/e4ef85c2290741399b9058243dfe71a2.jpg\n",
            "Saved: data/positive/987a1c5dd5fa4d13985923610b84134a.jpg\n",
            "Saved: data/positive/9b109b59be69408aadb3ac7a0cf8e755.jpg\n",
            "Saved: data/positive/a5e516b065e144249f612733d82a3822.jpg\n",
            "Saved: data/positive/bf06ee87460b4f87a05cccfbf341830f.jpg\n",
            "Saved: data/positive/2de9ff0d083d4197956a805847d10f41.jpg\n",
            "No face detected in 000281.jpg. Skipping.\n",
            "Saved: data/positive/a0808a36e5734d39a96b69df5204465c.jpg\n",
            "Saved: data/positive/a7f733e55f8842b5985cb03c3b871182.jpg\n",
            "Saved: data/positive/831e5c09498e45a9989b61512b6ddee0.jpg\n",
            "Saved: data/positive/94502b77c0724f8f8dba0d36b2da6c6f.jpg\n",
            "Saved: data/positive/2da2fba25fdc4863b5833f2e59f0cd37.jpg\n",
            "Saved: data/positive/dfec78aace314d7ea0190cc548659939.jpg\n",
            "Saved: data/positive/ad9512862455479688301d115cec86ce.jpg\n",
            "Saved: data/positive/65b143ba275f4d89b54f9a34bda4ac72.jpg\n",
            "Saved: data/positive/5b0da0c971ff4227b8da5840d3e92bbe.jpg\n",
            "Saved: data/positive/e681e3c08e574623a03a51186bb9d08e.jpg\n",
            "Saved: data/positive/3311037b7a6a4d15a2ea74446c5a3450.jpg\n",
            "Saved: data/positive/2277149496bc4555b42cf070c2122093.jpg\n",
            "Saved: data/positive/4b57cce029de49018f37fe0b2438cd66.jpg\n",
            "Saved: data/positive/26a9b853007c4b5999257b45180f1d07.jpg\n",
            "Saved: data/positive/24aa15fdd94f41d38d2ce114aba383bc.jpg\n",
            "Saved: data/positive/b15a8ea6edc5488eac9f20f5e7754bbf.jpg\n",
            "Saved: data/positive/5a4aac086a07419283e16866c95db50c.jpg\n",
            "Saved: data/positive/9f44f31066814f43ac4e2c9152c756db.jpg\n",
            "Saved: data/positive/08a6490f4c8147818200dc9a79224fcf.jpg\n",
            "Saved: data/positive/217e43ffc9cb49aebeca103a17fd6526.jpg\n",
            "Saved: data/positive/f2bda757f1b54c129c74bbea27e80241.jpg\n",
            "Saved: data/positive/1f1159db78224411a0dfcc1739771ccc.jpg\n",
            "Saved: data/positive/62192aadf5c44f30b6561158472fc6fc.jpg\n",
            "Saved: data/positive/4f3cf6f70c4e4aa0b0fc42542fdee831.jpg\n",
            "Saved: data/positive/0741cf14177047408d9ef4ced7bdff83.jpg\n",
            "Saved: data/positive/d734e066171e451ba0f487f8bf645a3d.jpg\n",
            "Saved: data/positive/89b68ca0fd0b4666963d367aae5c9fca.jpg\n",
            "Saved: data/positive/e7ca7bab081f4e20b81cdf17e31bf166.jpg\n",
            "Saved: data/positive/2fc7ab47339a4c3c8ef9abfdbba3d235.jpg\n",
            "Saved: data/positive/6565cc0e20dc4337b5a6a43732bf1f25.jpg\n",
            "Saved: data/positive/2d91fb281c124b29ae52d89f3ba8087a.jpg\n",
            "Saved: data/positive/e1ae37e250a3440fbf2055f31726a389.jpg\n",
            "Saved: data/positive/72a0e9fc69d642f58b198432f4a67409.jpg\n",
            "Saved: data/positive/73dbe5357d6740acb604d46d44adc18b.jpg\n",
            "Saved: data/positive/81b261081f40405bbbc493613389ea8b.jpg\n",
            "Saved: data/positive/a4783fa4763341fea012d93cac48e824.jpg\n",
            "Saved: data/positive/20b6f0ccdaad4d29bbc506feca5c4e5a.jpg\n",
            "Saved: data/positive/393e30f96a4d4cb997515242b7202661.jpg\n",
            "No face detected in 000283.jpg. Skipping.\n",
            "Saved: data/positive/88f476215464406a97214fe6794017ea.jpg\n",
            "Saved: data/positive/dec87dbcf57e4bc2b684de6b44c83a59.jpg\n",
            "No face detected in 000141.jpg. Skipping.\n",
            "Saved: data/positive/3fcc6be2513a40189b260bbdb077e0de.jpg\n",
            "Saved: data/positive/ffdc1a4e365b4365a744c168ab2807ce.jpg\n",
            "Saved: data/positive/83c34001958449d98b4c6abf96d398e6.jpg\n",
            "Saved: data/positive/39426202044e4bed8719aca27024dfb3.jpg\n",
            "Saved: data/positive/07739980fe8447228e537c051706d4c7.jpg\n",
            "Saved: data/positive/850319d3a5a545d69e7fe0feb1c57324.jpg\n",
            "Saved: data/positive/033e4fd05a6d4e298e65d67719e9a49d.jpg\n",
            "Saved: data/positive/ea023d97e4464327ace55ddd06ebac86.jpg\n",
            "Saved: data/positive/51d4655b48f74a26b9399ee8a94cfb12.jpg\n",
            "Saved: data/positive/009a0b20e45544998d71c005a2b215d1.jpg\n",
            "No face detected in 000266.jpg. Skipping.\n",
            "Saved: data/positive/e98ba3d35e794091a1acde291cccd063.jpg\n",
            "Saved: data/positive/df07c92e57c349eb82c907d950ba734e.jpg\n",
            "Saved: data/positive/4892bb1351714aeeb8f4bf9bcdf8e6e0.jpg\n",
            "Saved: data/positive/1144169f285f42428a05fe00263ae285.jpg\n",
            "Saved: data/positive/15c2772b57514b358207e69c02786fb7.jpg\n",
            "Saved: data/positive/13b90caa034b4d8abd6b3f94965afe92.jpg\n",
            "Saved: data/positive/3df225338ee44b5fbed5804bc13a5b76.jpg\n",
            "Saved: data/positive/6d0ed5d8b8b54ba385e7121a9d439fed.jpg\n",
            "Saved: data/positive/7719d4c9f3a14e98a809107c7e9aeb13.jpg\n",
            "Saved: data/positive/0f1d8306134346b0a522edf440224f26.jpg\n",
            "Saved: data/positive/e6303d527bfe405cb84ac89b96ee31ab.jpg\n",
            "Saved: data/positive/d3d5184d87af49d9b6ee60a104f2dea3.jpg\n",
            "Saved: data/positive/85f425fc92234bdda48397c3e62588ce.jpg\n",
            "Saved: data/positive/da52bc54a8784f298c842428ad077172.jpg\n",
            "Saved: data/positive/fa7a4e4b282d40d1a8c5c51a5be338df.jpg\n",
            "Saved: data/positive/449ee2e33a994e3f9ad39d22c55da3c3.jpg\n",
            "Saved: data/positive/9d77890b148d4912aafaa22a5facc77e.jpg\n",
            "Saved: data/positive/43e701efae8b419fa9e388bb0ceb621b.jpg\n",
            "Saved: data/positive/6ef204f57114429cb2963cb6e00da48f.jpg\n",
            "Saved: data/positive/7cfe058674f74afb82ca2b7aefa8f016.jpg\n",
            "Saved: data/positive/6c37ef4d27f240399244cd91c0a182c9.jpg\n",
            "Saved: data/positive/6ba3743ed9bb432aa095818eeadf146e.jpg\n",
            "Saved: data/positive/42311403efe24a8fb6f0005ca02d1362.jpg\n",
            "Saved: data/positive/62b97ffebdd74ea0b09b94fd2837bca9.jpg\n",
            "Saved: data/positive/0133c96281da45a9a41d4cf215edad6e.jpg\n",
            "Saved: data/positive/d43026637c3348fa90e8e7f5ce948c30.jpg\n",
            "Saved: data/positive/0e8aef065b81454596ee587f0ed84279.jpg\n",
            "Saved: data/positive/c234093ff6034e84b672b117cef5441b.jpg\n",
            "Saved: data/positive/446f7ddb6c4b4bb48fa4d4fff7f3730c.jpg\n",
            "Saved: data/positive/61c74311604540929c6072f6dcaeccbb.jpg\n",
            "Saved: data/positive/bb9f1cea3f0f4ef0b3b6a23275bff04d.jpg\n",
            "Saved: data/positive/58234a91cb7c4c3690283eddcb4fc491.jpg\n",
            "Saved: data/positive/539abdc5521146d2a8d8c205ee57b3c7.jpg\n",
            "Saved: data/positive/4e9f19dbc3da477ea11c6f2c32b1f670.jpg\n",
            "Saved: data/positive/16b7031489244115bd62dedbc820b057.jpg\n",
            "Saved: data/positive/eefd9bf8efda40c09695ea0058fb7c3f.jpg\n",
            "Saved: data/positive/c7c3de1eab3e4ae7b2aa39069a653a2e.jpg\n",
            "Saved: data/positive/7a50ccee1f7a4160bbbc9555ac721619.jpg\n",
            "Saved: data/positive/12c77305d92d4f5793aa5b00d060f1b1.jpg\n",
            "Saved: data/positive/22c8faf571e84af38575d5bfc3f65b67.jpg\n",
            "No face detected in 000262.jpg. Skipping.\n",
            "Saved: data/positive/c5a23613ef9243ea8dae6fa09e2465b3.jpg\n",
            "Saved: data/positive/46c4862e80f74e79b6202bce2a2a1cfc.jpg\n",
            "Saved: data/positive/c7213bf9ffb24a109a5e73ae3b099469.jpg\n",
            "Saved: data/positive/87948290777d458a8bf59c8479a1e88b.jpg\n",
            "Saved: data/positive/89830e3942c54e7fbc141fd5cb6fc675.jpg\n",
            "Saved: data/positive/9861f70829ba47eea3cd05ccb05615ee.jpg\n",
            "Saved: data/positive/821727edd9314237ac9ec564f16e8d3d.jpg\n",
            "Saved: data/positive/bbd626610bde4c0f81d862b757ceeeb3.jpg\n",
            "Saved: data/positive/222ec23010bf431993069d9beb515477.jpg\n",
            "Saved: data/positive/f3812a02ad3d475687ac4d65f32bde67.jpg\n",
            "Saved: data/positive/a068938c95904726a762a1ac0b773476.jpg\n",
            "No face detected in 000277.jpg. Skipping.\n",
            "Saved: data/positive/ffc6ab67b111465784e981dfaf9be5dc.jpg\n",
            "Saved: data/positive/d638e2f8b47d430183d8cc014e08421f.jpg\n",
            "Saved: data/positive/5598bf8b05184f7e8fb49e04fd52b540.jpg\n",
            "Saved: data/positive/81ff176257b4492783639bf37ac7a5df.jpg\n",
            "Saved: data/positive/d9d450f2ae6d4bc785e9a82c4a4a8686.jpg\n",
            "Saved: data/positive/e5a14ad349e6499685ebbff32eb696cf.jpg\n",
            "Saved: data/positive/e1d26e5745f94e65a8092f6af8bcacfd.jpg\n",
            "Saved: data/positive/2d7242c66b5142e280e68a8cb35c06b3.jpg\n",
            "Saved: data/positive/9567c5bd3d7341159508c81e656bc6b0.jpg\n",
            "Saved: data/positive/845e43832c05456892124c72ae14d0f3.jpg\n",
            "No face detected in 000263.jpg. Skipping.\n",
            "Saved: data/positive/6d586f33d7f24dcb9ecec293f6f47ac6.jpg\n",
            "Saved: data/positive/a425b96a787941c9b46754abd4afac0e.jpg\n",
            "Saved: data/positive/5ecc7e18bf3a4457966df89553c22ba9.jpg\n",
            "Saved: data/positive/0ceedf90d6f44c3db35fff7b4e5aade5.jpg\n",
            "Saved: data/positive/44bba7c14d8045579edd9ae51a2ec6e6.jpg\n",
            "Saved: data/positive/4c0487911e164fa3af3f0cc5a70b3aa2.jpg\n",
            "Saved: data/positive/a98d1afae6fe4a90bb47a7bb45b745ca.jpg\n",
            "Saved: data/positive/f85ed38119514406b544a9fe349942cc.jpg\n",
            "Saved: data/positive/7e83dc252fe143baa4ee67168d459dd6.jpg\n",
            "Saved: data/positive/28787b7605694de1b98467681699c02e.jpg\n",
            "Saved: data/positive/fb308c4acbdd4a338ce25733c27fc6d6.jpg\n",
            "Saved: data/positive/bc88f8699bef4a1e87632141122913fe.jpg\n",
            "Saved: data/positive/37686a9addd741a3b0873407962b88fd.jpg\n",
            "No face detected in 000273.jpg. Skipping.\n",
            "Saved: data/positive/71f5db2e11cc487fb5b6483044ab7f52.jpg\n",
            "Saved: data/positive/0aeec0d7311f41c9a88d11ce120d09ea.jpg\n",
            "Saved: data/positive/5fb3d8664f484d96af2ab4d3ceda670a.jpg\n",
            "Saved: data/positive/4b041dd5c2304566aab317a6f7dd44ca.jpg\n",
            "Saved: data/positive/33e31634ba7143498bc4e8e8dcea4055.jpg\n",
            "Saved: data/positive/8b71638069fc4feaa75db072d32b8b2a.jpg\n",
            "Saved: data/positive/bb4bbedad56d45029ae1050d86a793a4.jpg\n",
            "No face detected in 000271.jpg. Skipping.\n",
            "Saved: data/positive/d7c7221cca184718a43f63b1bb4b3df0.jpg\n",
            "Saved: data/positive/1a89567002324dfca1ffff02763f215e.jpg\n",
            "Saved: data/positive/2ea4446227984e67b4bd91b49d6a97c9.jpg\n",
            "Saved: data/positive/fe3acefd02f8488da0a89a287e0ab9b3.jpg\n",
            "Saved: data/positive/d6eccd09a36244e2867421a72d6dda23.jpg\n",
            "Saved: data/positive/6a450e8242f44cc4938cfc98c2e1af62.jpg\n",
            "Saved: data/positive/c3d2a4953ec64c58ba24ffe054d7a970.jpg\n",
            "Saved: data/positive/76fac6c6b3f24162bf6330070460e238.jpg\n",
            "Saved: data/positive/66db58c828124463b514589481a8ecc0.jpg\n",
            "Saved: data/positive/9bc6d43b3cda4db0bfab53a1fa290b32.jpg\n",
            "Saved: data/positive/78526ca6a035466390edaa768f5c8304.jpg\n",
            "Saved: data/positive/9353141f5e2e4e1e9e0810b33c44904a.jpg\n",
            "Saved: data/positive/dc1d638ae75d44e6b7aeb416d4701ef6.jpg\n",
            "Saved: data/positive/86095aa075ca4d16ab52877d6442f064.jpg\n",
            "Saved: data/positive/a92d6ad05a1842fca657bc88c77ae23c.jpg\n",
            "Saved: data/positive/08b56d1151384a34a80c9e62849c0189.jpg\n",
            "Saved: data/positive/39e7e172bdb449eab12401e08f89e0b3.jpg\n",
            "Saved: data/positive/f40827127c094c95887665efb01948cc.jpg\n",
            "Saved: data/positive/b350a892b94e42a080be0d1a2f8d1cc2.jpg\n",
            "Saved: data/positive/4e83e6f4341047f99670091109fc5a94.jpg\n",
            "Saved: data/positive/dec1d7a5f7f94f129a8bbe280d34ae3e.jpg\n",
            "Saved: data/positive/ead643ee886d42c780a97793087cbc5f.jpg\n",
            "Saved: data/positive/831922d0135c4d0985c947f1e1d2938a.jpg\n",
            "Saved: data/positive/742efacc26ec4b02b0a8dc5827ee94bc.jpg\n",
            "Saved: data/positive/0d290e32514a45e7b255873cc921daf9.jpg\n",
            "Saved: data/positive/72e59f42706c4e37b01bed270dce0eb3.jpg\n",
            "Saved: data/positive/f4924f53fee0403b90b7b4c3d1cc5ed7.jpg\n",
            "Saved: data/positive/63ab628f499a48578d114c3b3cad22a7.jpg\n",
            "Saved: data/positive/0bf8d177e6904ed284231af73fbf6659.jpg\n",
            "Saved: data/positive/356ed977141f479a83e2a856f5a5e987.jpg\n",
            "Saved: data/positive/593971addb8744ff815ed5e05f75be22.jpg\n",
            "Saved: data/positive/4e3ed29af6cc4bb8a398ee167d3250e0.jpg\n",
            "Saved: data/positive/cfdf8544f518413b97804585691cb6d4.jpg\n",
            "Saved: data/positive/21859e23c2034e2ca2222a1a7d925b70.jpg\n",
            "Saved: data/positive/42ae644e5f204d959ea55f00364b6663.jpg\n",
            "Saved: data/positive/956f3664bb46444bb2c8dae9e1cbaaef.jpg\n",
            "Saved: data/positive/18e24fbf2c69403aa0c58445c73b5702.jpg\n",
            "Saved: data/positive/e75a7a595a0f460292fbe8ed5b3556b4.jpg\n",
            "Saved: data/positive/1b117a42440a481d9b5239dc77bd24eb.jpg\n",
            "Saved: data/positive/1ecdc98843874291a23e4f55e4a1d369.jpg\n",
            "Saved: data/positive/6ee5e51048904573b43a1d8c54de332e.jpg\n",
            "Saved: data/positive/55ddcd40aabc409bb18a08da8d3a0205.jpg\n",
            "Saved: data/positive/ac106dc6db9b47e4a0130038d1ab9437.jpg\n",
            "Saved: data/positive/b0fac9750f7d442f9e6742cb17482bcd.jpg\n",
            "Saved: data/positive/ea78f9d5b1674a78b4f59b00fb1b531f.jpg\n",
            "Saved: data/positive/843a7aaeb3cd41c5a713c5718d2cda7d.jpg\n",
            "Saved: data/positive/54821cde2ed84e4e9b1601b6e98693ab.jpg\n",
            "Saved: data/positive/fc5923ecf5c64608bea86b9068eb1f4c.jpg\n",
            "Saved: data/positive/b0c15435150b49f7ac170cb4d505436e.jpg\n",
            "Saved: data/positive/4da7ac1136924852868f90ef38868972.jpg\n",
            "Saved: data/positive/be14f2e5345146e487261f4a0dad4b2c.jpg\n",
            "Saved: data/positive/4ca71814c0344fa8ace9d9a6774d5378.jpg\n",
            "Saved: data/positive/e5c0ab8abb0543fd8f93757df760c1e5.jpg\n",
            "Saved: data/positive/82a0e4ce61ff4ff4b3bed9688cb9692d.jpg\n",
            "Saved: data/positive/86aae67f122b409a9819484f356a5686.jpg\n",
            "Saved: data/positive/65ad60657ae0470bb99752332ea99e39.jpg\n",
            "Saved: data/positive/eea5a889763d430c9f59a8780d7768b3.jpg\n",
            "Saved: data/positive/e5d7c12057da438590b7d3e2e0d853e7.jpg\n",
            "Saved: data/positive/d987a5e72a3341ab952304b5884ad7de.jpg\n",
            "Saved: data/positive/e4cd690892934a359baf4a49a248e387.jpg\n",
            "Saved: data/positive/771182f5d91a46ebb7e99fe6637fe3de.jpg\n",
            "Saved: data/positive/214579be7715481b97ce7635ac99cb74.jpg\n",
            "Saved: data/positive/c7bf27f8765142afa8766d494dfaa14f.jpg\n",
            "Saved: data/positive/38ef4d4c4afb49519120485797de628a.jpg\n",
            "Total images saved: 271\n",
            "Temporary images folder removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_and_store_anchor_images(person_name, num_images, anchor_path):\n",
        "    \"\"\"\n",
        "    Scrapes images of a specified person and saves all processed images to the anchor path.\n",
        "\n",
        "    Parameters:\n",
        "    - person_name (str): The name of the person to search for.\n",
        "    - num_images (int): The number of images to download.\n",
        "    - anchor_path (str): The directory path where anchor images will be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure the anchor directory exists\n",
        "    if not os.path.exists(anchor_path):\n",
        "        os.makedirs(anchor_path)\n",
        "        print(f\"Created directory: {anchor_path}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {anchor_path}\")\n",
        "\n",
        "    # Initialize the Bing crawler to download images\n",
        "    crawler = BingImageCrawler(storage={\"root_dir\": \"temp_images\"})\n",
        "    print(f\"Starting image crawl for '{person_name}' with max_num={num_images}\")\n",
        "    crawler.crawl(keyword=person_name, max_num=num_images)\n",
        "    print(\"Image crawling completed.\")\n",
        "\n",
        "    # List all downloaded image files\n",
        "    image_files = [f for f in os.listdir(\"temp_images\") if f.lower().endswith(('jpg', 'jpeg', 'png'))]\n",
        "    print(f\"Number of images downloaded: {len(image_files)}\")\n",
        "\n",
        "    if not image_files:\n",
        "        raise FileNotFoundError(\"No images were downloaded. Please refine your search query.\")\n",
        "\n",
        "    # Initialize MTCNN for face detection\n",
        "    detector = MTCNN()\n",
        "    saved_count = 0\n",
        "\n",
        "    for idx, image_file in enumerate(image_files):\n",
        "        image_path = os.path.join(\"temp_images\", image_file)\n",
        "        try:\n",
        "            # Open and convert image to RGB\n",
        "            downloaded_image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_np = np.array(downloaded_image)\n",
        "\n",
        "            # Detect faces in the image\n",
        "            faces = detector.detect_faces(image_np)\n",
        "            if faces:\n",
        "                # Get the first detected face's bounding box\n",
        "                x, y, width, height = faces[0][\"box\"]\n",
        "\n",
        "                # Expand the bounding box by 30%\n",
        "                expansion_factor = 0.3\n",
        "                x_expand = int(width * expansion_factor)\n",
        "                y_expand = int(height * expansion_factor)\n",
        "\n",
        "                # Calculate new bounding box coordinates with expansion\n",
        "                x_new = max(0, x - x_expand)\n",
        "                y_new = max(0, y - y_expand)\n",
        "                width_new = min(downloaded_image.width, x + width + x_expand) - x_new\n",
        "                height_new = min(downloaded_image.height, y + height + y_expand) - y_new\n",
        "\n",
        "                # Crop the expanded face region\n",
        "                cropped_face = downloaded_image.crop((x_new, y_new, x_new + width_new, y_new + height_new))\n",
        "\n",
        "                # Pad to maintain aspect ratio\n",
        "                max_side = max(cropped_face.size)\n",
        "                padded_face = ImageOps.expand(\n",
        "                    cropped_face,\n",
        "                    border=(max_side - cropped_face.width) // 2,\n",
        "                    fill=(0, 0, 0)\n",
        "                )\n",
        "\n",
        "                # Resize to 250x250 pixels\n",
        "                resized_face = padded_face.resize((250, 250))\n",
        "\n",
        "                # Generate a unique filename and save the image to the anchor path\n",
        "                filename = f\"{uuid.uuid4().hex}.jpg\"\n",
        "                save_path_full = os.path.join(anchor_path, filename)\n",
        "                resized_face.save(save_path_full)\n",
        "\n",
        "                # print(f\"Saved: {save_path_full}\")\n",
        "                saved_count += 1\n",
        "            else:\n",
        "                print(f\"No face detected in {image_file}. Skipping.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_file}: {e}\")\n",
        "\n",
        "    print(f\"Total images saved to anchor: {saved_count}\")\n",
        "\n",
        "    # Clean up temporary images\n",
        "    shutil.rmtree(\"temp_images\")\n",
        "    print(\"Temporary images folder removed.\")\n",
        "\n",
        "# Example usage\n",
        "ANCHOR_PATH = os.path.join('data', 'anchor')\n",
        "scrape_and_store_anchor_images(\n",
        "    person_name=\"Elon Musk\",\n",
        "    num_images=400,  # Adjust as needed\n",
        "    anchor_path=ANCHOR_PATH\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pUEmfofCIpI",
        "outputId": "3fd92894-a7de-4d67-f422-51ebf4d1c324"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory already exists: data/anchor\n",
            "Starting image crawl for 'Elon Musk' with max_num=400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Exception caught when downloading file https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/7GZY2GHEDQI6XCGFJ7LDQLCHZM.jpg, error: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=5), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/7GZY2GHEDQI6XCGFJ7LDQLCHZM.jpg, error: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=5), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/7GZY2GHEDQI6XCGFJ7LDQLCHZM.jpg, error: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=5), remaining retry times: 0\n",
            "ERROR:downloader:Response status code 520, file https://itrenting.com/wp-content/uploads/2017/04/elon-musk.jpg\n",
            "ERROR:downloader:Response status code 403, file https://www.theladders.com/wp-content/uploads/Elon_Musk.jpg\n",
            "ERROR:downloader:Exception caught when downloading file https://apidyn.royalsociety.org/images/fellows/P37009-Elon-Musk.jpg, error: HTTPSConnectionPool(host='apidyn.royalsociety.org', port=443): Max retries exceeded with url: /images/fellows/P37009-Elon-Musk.jpg (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://apidyn.royalsociety.org/images/fellows/P37009-Elon-Musk.jpg, error: HTTPSConnectionPool(host='apidyn.royalsociety.org', port=443): Max retries exceeded with url: /images/fellows/P37009-Elon-Musk.jpg (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://apidyn.royalsociety.org/images/fellows/P37009-Elon-Musk.jpg, error: HTTPSConnectionPool(host='apidyn.royalsociety.org', port=443): Max retries exceeded with url: /images/fellows/P37009-Elon-Musk.jpg (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))), remaining retry times: 0\n",
            "ERROR:downloader:Response status code 403, file https://www.ccn.com/wp-content/uploads/2019/04/elon-musk-tesla-red.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image crawling completed.\n",
            "Number of images downloaded: 244\n",
            "No face detected in 000142.jpg. Skipping.\n",
            "Total images saved to anchor: 243\n",
            "Temporary images folder removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "def preprocess(file_path):\n",
        "  img=Image.open(file_path.convet(\"RGB\"))\n",
        "\n",
        "  transform=transforms.Compose([\n",
        "      transforms.Resize((100,100)),\n",
        "      transform.ToTensor(),\n",
        "  ])\n",
        "  img=transforms(img)\n",
        "  return img"
      ],
      "metadata": {
        "id": "LpE7833VCNWG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "\n",
        "class AnchorValidationDataset(Dataset):\n",
        "    def __init__(self, anchor_paths, validation_paths, labels, transform=None):\n",
        "        \"\"\"\n",
        "        Custom dataset for pairing anchors with validation images (positives and negatives).\n",
        "        Args:\n",
        "            anchor_paths (list): List of anchor image paths.\n",
        "            validation_paths (list): List of validation image paths (positives and negatives).\n",
        "            labels (list): Corresponding labels for validation images (1 for positive, 0 for negative).\n",
        "            transform (callable): Transformations to apply to images.\n",
        "        \"\"\"\n",
        "        self.anchor_paths = anchor_paths\n",
        "        self.validation_paths = validation_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load anchor and validation images\n",
        "        anchor = Image.open(self.anchor_paths[idx]).convert(\"RGB\")\n",
        "        validation = Image.open(self.validation_paths[idx]).convert(\"RGB\")\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            anchor = self.transform(anchor)\n",
        "            validation = self.transform(validation)\n",
        "\n",
        "        # Get the label\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "        return anchor, validation, label\n",
        "\n",
        "\n",
        "# Specify the limit and transformations\n",
        "limit = 100\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.RandomHorizontalFlip(),  # Augmentation example\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Anchor and validation image paths\n",
        "anchor_files = sorted([os.path.join(ANC_PATH, f) for f in os.listdir(ANC_PATH) if f.endswith('.jpg')])\n",
        "positive_files = sorted([os.path.join(POS_PATH, f) for f in os.listdir(POS_PATH) if f.endswith('.jpg')])\n",
        "negative_files = sorted([os.path.join(NEG_PATH, f) for f in os.listdir(NEG_PATH) if f.endswith('.jpg')])\n",
        "\n",
        "# Ensure we have exactly 300 positives and 300 negatives\n",
        "positive_files = positive_files[:limit]\n",
        "negative_files = negative_files[:limit]\n",
        "\n",
        "# Double the anchors to ensure sufficient pairs\n",
        "anchor_files = anchor_files[:limit] * 2  # Now we have 600 anchors\n",
        "\n",
        "# Combine validation paths and labels\n",
        "validation_paths = positive_files + negative_files\n",
        "labels = [1] * len(positive_files) + [0] * len(negative_files)\n",
        "\n",
        "# Ensure anchors match validation pairs (300 positive + 300 negative = 600 validation pairs)\n",
        "if len(anchor_files) != len(validation_paths):\n",
        "    raise ValueError(\"Number of anchors must match the total number of validation pairs.\")\n",
        "\n",
        "# Create the dataset\n",
        "dataset = AnchorValidationDataset(anchor_files, validation_paths, labels, transform=transform)\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "for batch in dataloader:\n",
        "    anchor, validation, label = batch\n",
        "    print(f\"Anchor shape: {anchor.shape}, Validation shape: {validation.shape}, Label shape: {label.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktqD8zoBGmKM",
        "outputId": "42017713-3ecf-4d7f-e56b-951a6667f7da"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anchor shape: torch.Size([32, 3, 100, 100]), Validation shape: torch.Size([32, 3, 100, 100]), Label shape: torch.Size([32])\n",
            "Anchor shape: torch.Size([32, 3, 100, 100]), Validation shape: torch.Size([32, 3, 100, 100]), Label shape: torch.Size([32])\n",
            "Anchor shape: torch.Size([32, 3, 100, 100]), Validation shape: torch.Size([32, 3, 100, 100]), Label shape: torch.Size([32])\n",
            "Anchor shape: torch.Size([32, 3, 100, 100]), Validation shape: torch.Size([32, 3, 100, 100]), Label shape: torch.Size([32])\n",
            "Anchor shape: torch.Size([32, 3, 100, 100]), Validation shape: torch.Size([32, 3, 100, 100]), Label shape: torch.Size([32])\n",
            "Anchor shape: torch.Size([32, 3, 100, 100]), Validation shape: torch.Size([32, 3, 100, 100]), Label shape: torch.Size([32])\n",
            "Anchor shape: torch.Size([8, 3, 100, 100]), Validation shape: torch.Size([8, 3, 100, 100]), Label shape: torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0oapet6qsNd",
        "outputId": "10f7ee7b-d5aa-4a9b-ae3c-1a1df30f93c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.layers = nn.Sequential(\n",
        "            # First Layer\n",
        "            nn.Conv2d(in_channels, out_channels=64, kernel_size=10),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, padding=1),  # Removed padding=1\n",
        "            # Second Layer\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=7),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, padding=1),  # Removed padding=1\n",
        "            # Third Layer\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),  # Removed padding=1\n",
        "            # Fourth Layer\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        # Dynamically calculate the input size for the Linear layer\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, in_channels, 100, 100)  # Batch size 1, 3 channels, 100x100 image\n",
        "            flattened_size = self.layers(dummy_input).shape[1]\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(flattened_size, 4096),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = Embedding()\n",
        "\n",
        "# Print model summary\n",
        "summary(model, input_size=(1, 3, 100, 100))  # Batch size 1, 3 channels, 100x100 image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4A8FyMpqTql",
        "outputId": "85d441c7-fc2c-4d47-81c6-56194c08561f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Embedding                                [1, 4096]                 --\n",
              "├─Sequential: 1-1                        [1, 9216]                 --\n",
              "│    └─Conv2d: 2-1                       [1, 64, 91, 91]           19,264\n",
              "│    └─ReLU: 2-2                         [1, 64, 91, 91]           --\n",
              "│    └─MaxPool2d: 2-3                    [1, 64, 46, 46]           --\n",
              "│    └─Conv2d: 2-4                       [1, 128, 40, 40]          401,536\n",
              "│    └─ReLU: 2-5                         [1, 128, 40, 40]          --\n",
              "│    └─MaxPool2d: 2-6                    [1, 128, 21, 21]          --\n",
              "│    └─Conv2d: 2-7                       [1, 128, 18, 18]          262,272\n",
              "│    └─ReLU: 2-8                         [1, 128, 18, 18]          --\n",
              "│    └─MaxPool2d: 2-9                    [1, 128, 9, 9]            --\n",
              "│    └─Conv2d: 2-10                      [1, 256, 6, 6]            524,544\n",
              "│    └─ReLU: 2-11                        [1, 256, 6, 6]            --\n",
              "│    └─Flatten: 2-12                     [1, 9216]                 --\n",
              "├─Sequential: 1-2                        [1, 4096]                 --\n",
              "│    └─Linear: 2-13                      [1, 4096]                 37,752,832\n",
              "│    └─Sigmoid: 2-14                     [1, 4096]                 --\n",
              "==========================================================================================\n",
              "Total params: 38,960,448\n",
              "Trainable params: 38,960,448\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 943.60\n",
              "==========================================================================================\n",
              "Input size (MB): 0.12\n",
              "Forward/backward pass size (MB): 6.32\n",
              "Params size (MB): 155.84\n",
              "Estimated Total Size (MB): 162.28\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "  def __init__(self,in_channels=3):\n",
        "    super(Embedding,self).__init__()\n",
        "    self.in_channels=in_channels\n",
        "    self.layers=nn.ModuleList([\n",
        "        nn.Conv2d(in_channels, out_channels=64, kernel_size=10),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, padding=1),  # Removed padding=1\n",
        "        # Second Layer\n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=7),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, padding=1),  # Removed padding=1\n",
        "        # Third Layer\n",
        "        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),  # Removed padding=1\n",
        "        # Fourth Layer\n",
        "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(256 * 6 * 6,out_features=4096),\n",
        "        nn.Sigmoid()\n",
        "    ]\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    for layer in self.layers:\n",
        "      x=layer(x)\n",
        "    return x\n",
        "\n",
        "model = Embedding()\n",
        "\n",
        "# # Create dummy input\n",
        "# dummy_input = torch.zeros(1, 3, 100, 100)  # Batch size 1, 3 channels, 100x100 image\n",
        "\n",
        "# # Forward pass\n",
        "# output = model(dummy_input)\n",
        "# print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "id": "dZQDMpKPml0R"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class L1Dist(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(L1Dist,self).__init__()\n",
        "\n",
        "  def forward(self,input_embedding, validation_embedding):\n",
        "    return torch.abs(input_embedding-validation_embedding)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "9EXwiDPW09dX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Siamese(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Siamese,self).__init__()\n",
        "    # self.input_image=input_image\n",
        "    # self.validation_image=validation_image\n",
        "    self.siamese_layer=L1Dist()\n",
        "    self.embedding=Embedding()\n",
        "    self.classifier=nn.Sequential(\n",
        "        nn.Linear(4096,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, input_image, validation_image):\n",
        "    distances=self.siamese_layer(self.embedding(input_image),self.embedding(validation_image))\n",
        "    output=self.classifier(distances)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "-t2citmj29RX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Siamese()\n",
        "input_image = torch.randn(1, 3, 100, 100)  # Batch size 1, RGB image 100x100\n",
        "validation_image = torch.randn(1, 3, 100, 100)\n",
        "output = model(input_image, validation_image)\n",
        "print(\"Output shape:\", output.shape)  # Should be [1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEMLIT4x6O9c",
        "outputId": "956df455-7120-4816-cb5c-3ed9ee13c3d2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "opt=optim.Adam(model.parameters(),lr=1e-4)\n",
        "binary_cross_loss=nn.BCELoss()\n"
      ],
      "metadata": {
        "id": "HIIdZ2Uo7EjD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),  # Save model weights\n",
        "    'optimizer_state_dict': opt.state_dict(),  # Save optimizer state\n",
        "    'epoch': epoch  # Save current epoch\n",
        "}, './checkpoint.pth')"
      ],
      "metadata": {
        "id": "G71SQhZHCrbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(dataloader))\n",
        "anchor, validation, label = batch\n",
        "def train_step(model, optimizer, criterion, anchor, validation, label):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    # Forward pass: compute predictions\n",
        "    output = model(anchor, validation)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(output, label)\n",
        "\n",
        "    # Backward pass: compute gradients\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update model parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n"
      ],
      "metadata": {
        "id": "UmRwjKaFCuJP"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, filename=\"checkpoint.pth\"):\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),  # Model weights\n",
        "        'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state\n",
        "        'epoch': epoch  # Current epoch\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "    print(f\"Checkpoint saved at epoch {epoch} to {filename}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"Epoch {epoch}/{epochs}\")\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        anchor, validation, label = batch\n",
        "        label = label.float().unsqueeze(-1)  # BCE expects float labels\n",
        "\n",
        "        # Train step\n",
        "        loss = train_step(model, opt, binary_cross_loss, anchor, validation, label)\n",
        "        epoch_loss += loss\n",
        "\n",
        "    print(f\"Epoch {epoch} Loss: {epoch_loss / len(dataloader):.4f}\")\n",
        "\n",
        "    # Save checkpoint every 2 epochs\n",
        "    if epoch % 2 == 0:\n",
        "        save_checkpoint(model, opt, epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xZHfR-BDeAR",
        "outputId": "caae38d1-51b8-4c67-8ad6-b7b9a8e6aaf4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Epoch 1 Loss: 0.4099\n",
            "Epoch 2/10\n",
            "Epoch 2 Loss: 0.3982\n",
            "Checkpoint saved at epoch 2 to checkpoint.pth\n",
            "Epoch 3/10\n",
            "Epoch 3 Loss: 0.3604\n",
            "Epoch 4/10\n",
            "Epoch 4 Loss: 0.2668\n",
            "Checkpoint saved at epoch 4 to checkpoint.pth\n",
            "Epoch 5/10\n",
            "Epoch 5 Loss: 0.3130\n",
            "Epoch 6/10\n",
            "Epoch 6 Loss: 0.2245\n",
            "Checkpoint saved at epoch 6 to checkpoint.pth\n",
            "Epoch 7/10\n",
            "Epoch 7 Loss: 0.2006\n",
            "Epoch 8/10\n",
            "Epoch 8 Loss: 0.2025\n",
            "Checkpoint saved at epoch 8 to checkpoint.pth\n",
            "Epoch 9/10\n",
            "Epoch 9 Loss: 0.1457\n",
            "Epoch 10/10\n",
            "Epoch 10 Loss: 0.1244\n",
            "Checkpoint saved at epoch 10 to checkpoint.pth\n"
          ]
        }
      ]
    }
  ]
}